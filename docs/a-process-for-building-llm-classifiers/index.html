
<!DOCTYPE html>


<html lang="en" data-content_root="../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>A Process for Building LLM Classifiers &#8212; Kasper Junge</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  <!--
    this give us a css class that will be invisible only if js is disabled
  -->
  <noscript>
    <style>
      .pst-js-only { display: none !important; }

    </style>
  </noscript>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=03e43079" />
  
  <!-- So that users can add custom icons -->
  <script src="../_static/scripts/fontawesome.js?digest=8878045cc6db502f8baf"></script>
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf" />

    <script src="../_static/documentation_options.js?v=187304be"></script>
    <script src="../_static/doctools.js?v=9bcbadda"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script async="async" src="https://www.googletagmanager.com/gtag/js?id=G-3CEVPVH0T7"></script>
    <script>
                window.dataLayer = window.dataLayer || [];
                function gtag(){ dataLayer.push(arguments); }
                gtag('js', new Date());
                gtag('config', 'G-3CEVPVH0T7');
            </script>
    <script>
                window.dataLayer = window.dataLayer || [];
                function gtag(){ dataLayer.push(arguments); }
                gtag('js', new Date());
                gtag('config', 'G-3CEVPVH0T7');
            </script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'a-process-for-building-llm-classifiers';</script>
    <link rel="author" title="About these documents" href="../about/" />
    <link rel="index" title="Index" href="../genindex/" />
    <link rel="search" title="Search" href="../search/" /> 
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  <meta name="docsearch:version" content="" />   
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <dialog id="pst-search-dialog">
    
<form class="bd-search d-flex align-items-center"
      action="../search/"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         placeholder="Search the docs ..."
         aria-label="Search the docs ..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
  </dialog>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
<div class="bd-header__inner bd-page-width">
  <button class="pst-navbar-icon sidebar-toggle primary-toggle" aria-label="Site navigation">
    <span class="fa-solid fa-bars"></span>
  </button>
  
  
  <div class="col-lg-3 navbar-header-items__start">
    
      <div class="navbar-item">

  
    
  

<a class="navbar-brand logo" href="../">
  
  
  
  
  
  
    <p class="title logo__title">Kasper Junge</p>
  
</a></div>
    
  </div>
  
  <div class="col-lg-9 navbar-header-items">
    
    <div class="me-auto navbar-header-items__center">
      
        <div class="navbar-item">
<nav>
  <ul class="bd-navbar-elements navbar-nav">
    
<li class="nav-item ">
  <a class="nav-link nav-internal" href="../about/">
    About me
  </a>
</li>

  </ul>
</nav></div>
      
    </div>
    
    
    <div class="navbar-header-items__end">
      
        <div class="navbar-item navbar-persistent--container">
          

<button class="btn search-button-field search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
 <i class="fa-solid fa-magnifying-glass"></i>
 <span class="search-button__default-text">Search</span>
 <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
</button>
        </div>
      
      
        <div class="navbar-item">

<button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" aria-label="Color mode" data-bs-title="Color mode"  data-bs-placement="bottom" data-bs-toggle="tooltip">
  <i class="theme-switch fa-solid fa-sun                fa-lg" data-mode="light" title="Light"></i>
  <i class="theme-switch fa-solid fa-moon               fa-lg" data-mode="dark"  title="Dark"></i>
  <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"  title="System Settings"></i>
</button></div>
      
    </div>
    
  </div>
  
  
    <div class="navbar-persistent--mobile">

<button class="btn search-button-field search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
 <i class="fa-solid fa-magnifying-glass"></i>
 <span class="search-button__default-text">Search</span>
 <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
</button>
    </div>
  

  
    <button class="pst-navbar-icon sidebar-toggle secondary-toggle" aria-label="On this page">
      <span class="fa-solid fa-outdent"></span>
    </button>
  
</div>

    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
        
      
      <dialog id="pst-primary-sidebar-modal"></dialog>
      <div id="pst-primary-sidebar" class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
      <div class="sidebar-header-items__center">
        
          
          
            <div class="navbar-item">
<nav>
  <ul class="bd-navbar-elements navbar-nav">
    
<li class="nav-item ">
  <a class="nav-link nav-internal" href="../about/">
    About me
  </a>
</li>

  </ul>
</nav></div>
          
        
      </div>
    
    
    
      <div class="sidebar-header-items__end">
        
          <div class="navbar-item">

<button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" aria-label="Color mode" data-bs-title="Color mode"  data-bs-placement="bottom" data-bs-toggle="tooltip">
  <i class="theme-switch fa-solid fa-sun                fa-lg" data-mode="light" title="Light"></i>
  <i class="theme-switch fa-solid fa-moon               fa-lg" data-mode="dark"  title="Dark"></i>
  <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"  title="System Settings"></i>
</button></div>
        
      </div>
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
<div class="ablog-sidebar-item ablog__postcard">
   
  <h2>
     
    <i class="fa fa-calendar"></i>
    
    <span>17 August 2023</span>
    
  </h2>
  <ul>
    <div class="ablog-sidebar-item ablog__postcard2">
   
  <li id="ablog-sidebar-item author ablog__author">
    <span>
      
      <i class="fa-fw fa fa-user"></i>
      
    </span>
     
    <a href="../blog/author/kasper-junge/">Kasper Junge</a>
      
  </li>
      
  <li id="ablog-sidebar-item tags ablog__tags">
    <span>
       
      <i class="fa-fw fa fa-tag"></i>
      
    </span>
     
    <a href="../blog/tag//"></a>
      
  </li>
   
</div>
  </ul>
</div>
</div>
        <div class="sidebar-primary-item">
<div class="ablog-sidebar-item ablog__recentposts">
  <h3>
    <a href="../blog/">Recent Posts</a>
  </h3>
  <ul>
     
    <li>
      <a href="../posts/2025/100-tips-tricks-hacks-and-methods-users-of-cursor-have-for-coding-with-ai-in-cursor/">
        23 March - 100 Tips, Tricks, Hacks, and Methods for Coding with AI in Cursor
      </a>
    </li>
    
    <li>
      <a href="../posts/2025/deepgemm/">
        26 February - Investigating the DeepSeek DeepGEMM Release
      </a>
    </li>
    
    <li>
      <a href="../posts/2025/how-i-created-a-free-blog-using-python-and-github-pages/">
        16 February - How I created a free blog using Python and GitHub Pages
      </a>
    </li>
    
    <li>
      <a href="../posts/2025/hello-ablog-world/">
        14 February - Hello Ablog World!
      </a>
    </li>
    
    <li>
      <a href="../text-classifiers-are-an-underrated-use-case-of-llms/">
        12 September - Text Classifiers are an Underrated Application of LLMs
      </a>
    </li>
    
  </ul>
</div>
</div>
        <div class="sidebar-primary-item">
<div class="ablog-sidebar-item ablog__tagcloud">
  <link
    rel="stylesheet"
    href="../_static/ablog/tagcloud.css"
    type="text/css"
  />
  <h3><a href="../blog/tag/">Tags</a></h3>
  <ul class="ablog-cloud">
     
    <li class="ablog-cloud ablog-cloud-5">
      <a href="../blog/tag//"></a>
    </li>
      
    <li class="ablog-cloud ablog-cloud-1">
      <a href="../blog/tag/github-pages/">GitHub Pages</a>
    </li>
      
    <li class="ablog-cloud ablog-cloud-1">
      <a href="../blog/tag/sphinx/">Sphinx</a>
    </li>
      
    <li class="ablog-cloud ablog-cloud-1">
      <a href="../blog/tag/tutorial/">Tutorial</a>
    </li>
     
  </ul>
</div>
</div>
        <div class="sidebar-primary-item">
<div class="ablog-sidebar-item ablog__categories">
  <h3>
    <a href="../blog/category/">Categories</a>
  </h3>
  <ul>
     
    <li>
      <a href="../blog/category/ai-coding/">AI Coding (1)</a>
    </li>
     
  </ul>
</div>
</div>
        <div class="sidebar-primary-item">
<div class="ablog-sidebar-item ablog__archives">
  <h3>
    <a href="../blog/archive/">Archives</a>
  </h3>
  <ul>
     
    <li>
      <a href="../blog/2025/">2025 (4)</a>
    </li>
      
    <li>
      <a href="../blog/2023/">2023 (2)</a>
    </li>
     
  </ul>
</div>
</div>
        <div class="sidebar-primary-item">
<search id="searchbox" style="display: none" role="search">
    <div class="searchformwrapper">
    <form class="search" action="../search/" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" placeholder="Search"/>
      <input type="submit" value="Go" />
    </form>
    </div>
</search>
<script>document.getElementById('searchbox').style.display = "block"</script></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
      <div class="sidebar-primary-item">
<div id="ethical-ad-placement"
      class="flat"
      data-ea-publisher="readthedocs"
      data-ea-type="readthedocs-sidebar"
      data-ea-manual="true">
</div></div>
  </div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        
          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item">

<nav aria-label="Breadcrumb" class="d-print-none">
  <ul class="bd-breadcrumbs">
    
    <li class="breadcrumb-item breadcrumb-home">
      <a href="../" class="nav-link" aria-label="Home">
        <i class="fa-solid fa-home"></i>
      </a>
    </li>
    <li class="breadcrumb-item active" aria-current="page"><span class="ellipsis"><strong>A Process for Building LLM Classifiers</strong></span></li>
  </ul>
</nav>
</div>
      
    </div>
  
  
</div>
</div>
              
              
              
                
<div id="searchbox"></div>
                <article class="bd-article">
                   <section id="a-process-for-building-llm-classifiers">
<h1><strong>A Process for Building LLM Classifiers</strong><a class="headerlink" href="#a-process-for-building-llm-classifiers" title="Link to this heading">#</a></h1>
<p>Large language models (LLMs) can be prompt-engineered to solve a wide variety of tasks. While many consider chat as the primary use case, LLMs can also be used to build traditional classifiers.</p>
<p>Before the rise of advanced generative text-to-text models, crafting a custom text classifier was a time-consuming process that required extensive data collection and annotation.</p>
<p>Nowadays, you can get your hands dirty with LLMs without worrying about annotating data. This is great as it saves you a lot of time. However, it also becomes tempting to bypass best practices for building robust machine learning applications.</p>
<p>When there‚Äôs no need to create a training dataset, the temptation of simply hand-tuning a prompt based on a few examples becomes strong. You might convince yourself that it will generalize to any data that might be presented to it.The challenge is, without annotations to measure accuracy or a method to assess your prompt, you can‚Äôt determine its robustness once deployed.</p>
<p>In my recent work with LLMs, I have thought a lot about this and have developed a process that, in my experience, enables the construction of robust LLM classifiers. This method is not only more efficient but also more enjoyable to fine-tune compared to the old school way of doing it.</p>
<p>The following process will help you craft more robust and reliable LLM modules.</p>
<section id="step-1-collect-dataset">
<h2><strong>Step 1: Collect Dataset</strong><a class="headerlink" href="#step-1-collect-dataset" title="Link to this heading">#</a></h2>
<p>Collect a raw, unannotated dataset representative of the data on which your classifier will be used in real-world scenarios. The dataset‚Äôs size should provide the desired significance level when assessing the classifier, while remaining realistic for you to annotate and not exhausting your API call budget with OpenAI. Divide the dataset into validation and test subsets.</p>
<p>Step 2: Create Initial Prompt
Construct an initial prompt you believe will be effective. It should yield two outputs. The first output should articulate the model‚Äôs thoughts when determining which class to assign to the input text.</p>
<p>This will be useful for iterative improvements to the prompt, ensuring it aligns with the task. In accordance with the chain-of-thought method, this should improve its performance and enhance explainability. The second output should specify the class you want the LLM to categorize.</p>
<p>The output format should look something like this:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="o">{</span>
<span class="w">    </span><span class="s2">&quot;thoughts&quot;</span>:<span class="w"> </span>&lt;rationale<span class="w"> </span>behind<span class="w"> </span>classification<span class="w"> </span>here&gt;,
<span class="w">    </span><span class="s2">&quot;class&quot;</span>:<span class="w"> </span>&lt;the<span class="w"> </span>class<span class="w"> </span>the<span class="w"> </span>model<span class="w"> </span>has<span class="w"> </span>classified<span class="w"> </span>the<span class="w"> </span>example<span class="w"> </span>as<span class="w"> </span>here&gt;
<span class="o">}</span>
</pre></div>
</div>
<p>Test the prompt on a few dataset samples to get a feeling og the model‚Äôs comprehension of the task. Dedicate some time to refining it for optimal results. You should be confident that the LLM‚Äôs has a reasonable understanding of the task.</p>
</section>
<section id="step-3-run-inspect-and-annotate">
<h2><strong>Step 3: Run, Inspect and Annotate</strong><a class="headerlink" href="#step-3-run-inspect-and-annotate" title="Link to this heading">#</a></h2>
<p>Now run the hand-tuned prompt on the entire validation dataset.  For reproducibility, set the temperature to 0. Review all classified samples. If the LLM‚Äôs categorization is inaccurate, correct it and document areas of misunderstanding. Use the thoughts output to understand its decision-making process.</p>
<p>During annotation, you‚Äôll almost certainly discover complexities and nuances in the problem you‚Äôre trying solve that didn‚Äôt initially think of. Also you will likely discover ambiguities in the instruction you asked the LLM to follow, where you will have to be more clear in what you want it to do. In some cases the LLM‚Äôs limits of understanding will also reveal themselves. Document these findings in an ‚Äúannotation protocol‚Äù, which outlines rules for managing edge cases.</p>
</section>
<section id="step-4-measure-performance-of-prompt">
<h2><strong>Step 4: Measure Performance of Prompt</strong><a class="headerlink" href="#step-4-measure-performance-of-prompt" title="Link to this heading">#</a></h2>
<p>Upon completing step 3, you‚Äôll have an annotated validation dataset. This allows for the evaluation of the prompt‚Äôs predictive performance. Measure the performance to gain insight into the prompt‚Äôs predictive capabilities.</p>
</section>
<section id="step-5-adjust-prompt">
<h2><strong>Step 5: Adjust Prompt</strong><a class="headerlink" href="#step-5-adjust-prompt" title="Link to this heading">#</a></h2>
<p>Post step 5, you‚Äôll have written notes detailing cases where the LLM misclassified data. From this, formulate a hypothesis on potential prompt modifications to enhance its accuracy. Adjust the prompt in a which you think will mitigate the errors.</p>
</section>
<section id="step-6-iterate">
<h2><strong>Step 6: Iterate</strong><a class="headerlink" href="#step-6-iterate" title="Link to this heading">#</a></h2>
<p>After step 6, run the adjusted prompt on the validation dataset and measure its performance. Ideally, results should improve post-adjustment. Analyze incorrect classifications and take notes to understand the model‚Äôs behavior. Repeat this process until you are satisfied with the prompt‚Äôs performance or you believe that you have reached maximum performance.</p>
</section>
<section id="step-7-measure-performance-on-test-dataset">
<h2><strong>Step 7: Measure Performance on Test Dataset</strong><a class="headerlink" href="#step-7-measure-performance-on-test-dataset" title="Link to this heading">#</a></h2>
<p>Now is the time. It‚Äôs time to follow best practices, like the diligent and competent ML engineer you are. Now, you need to run the tuned prompt on a test set. However, your test set isn‚Äôt annotated yet, presenting a significant temptation to skip this step. But you know you have to do it! If you do this, you will likely find that performance on the test dataset is a little worse. This is expected and is because you have probably overfitted your prompt to the validation dataset.</p>
</section>
<section id="conclusion">
<h2><strong>Conclusion</strong><a class="headerlink" href="#conclusion" title="Link to this heading">#</a></h2>
<p>Congratulations, you now have an LLM classifier to solve a problem for you! For now, this is the best process I have. If you know of a better approach, I would love to hear from you. Additionally, at SEO.ai, where I work as an ML Engineer, we are constantly striving to crystallize our learnings into code. Specifically, we are developing a Python package called prompt-functions, which, in our experience, makes this process much smoother. We would love to continue the conversation on how to manage LLM applications, so please feel free to open an issue, send us a pull request or simply just reach out to me ü§ó</p>
</section>
</section>

<div class="section ablog__blog_comments">
     
<div class="section ablog__prev-next">
  <span class="ablog__prev">
    
  </span>
  <span class="ablog__spacer">&nbsp;</span>
  <span class="ablog__next">
     
    <a href="../text-classifiers-are-an-underrated-use-case-of-llms/">
      <span>Text Classifiers are an Underrated Application of LLMs</span>
      
      <i class="fa fa-arrow-circle-right"></i>
      
    </a>
    
  </span>
</div>
  
</div>

                </article>
              
              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
</div>
                </footer>
              
            </div>
            
            
              
                <dialog id="pst-secondary-sidebar-modal"></dialog>
                <div id="pst-secondary-sidebar" class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
<div
    id="pst-page-navigation-heading-2"
    class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> On this page
  </div>
  <nav class="bd-toc-nav page-toc" aria-labelledby="pst-page-navigation-heading-2">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#step-1-collect-dataset"><strong>Step 1: Collect Dataset</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#step-3-run-inspect-and-annotate"><strong>Step 3: Run, Inspect and Annotate</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#step-4-measure-performance-of-prompt"><strong>Step 4: Measure Performance of Prompt</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#step-5-adjust-prompt"><strong>Step 5: Adjust Prompt</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#step-6-iterate"><strong>Step 6: Iterate</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#step-7-measure-performance-on-test-dataset"><strong>Step 7: Measure Performance on Test Dataset</strong></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#conclusion"><strong>Conclusion</strong></a></li>
</ul>
  </nav></div>

  <div class="sidebar-secondary-item">
  <div role="note" aria-label="source link">
    <h3>This Page</h3>
    <ul class="this-page-menu">
      <li><a href="../_sources/a-process-for-building-llm-classifiers.rst.txt"
            rel="nofollow">Show Source</a></li>
    </ul>
   </div></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
          </footer>
        
      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script defer src="../_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf"></script>
<script defer src="../_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf"></script>

  <footer class="bd-footer">
<div class="bd-footer__inner bd-page-width">
  
    <div class="footer-items__start">
      
        <div class="footer-item">

  <p class="copyright">
    
      ¬© Copyright 2025, Kasper Junge.
      <br/>
    
  </p>
</div>
      
    </div>
  
  
  
    <div class="footer-items__end">
      
        <div class="footer-item">
<p class="theme-version">
  <!-- # L10n: Setting the PST URL as an argument as this does not need to be localized -->
  Built with the <a href="https://pydata-sphinx-theme.readthedocs.io/en/stable/index.html">PyData Sphinx Theme</a> 0.16.1.
</p></div>
      
    </div>
  
</div>

  </footer>
  </body>
</html>